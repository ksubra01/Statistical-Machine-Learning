{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import itertools as iter\n",
        "\n",
        "d = 784\n",
        "k = [2,5,10,20,40,80,160]#,320]\n",
        "\n",
        "########## Preprocessing the datat set ###########################\n",
        "# Obtain the data set\n",
        "(X_train, labels_train), (X_test, labels_test) = mnist.load_data()\n",
        "#mndata = MNIST(r'/content/train-images-idx3-ubyte.gz')\n",
        "#X_train, labels_train = map(np.array, mndata.load_training())\n",
        "#X_test, labels_test = map(np.array, mndata.load_testing())\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "\n",
        "X_train = X_train.reshape(60000,784)\n",
        "X_test = X_test.reshape(10000,784)\n",
        "n = X_train.shape[0]\n",
        "n1 = X_test.shape[0]\n",
        "##################################################################\n",
        "\n",
        "\n",
        "\n",
        "######### Function to assign random centorids #########################\n",
        "\n",
        "def random_centroids(x,k):\n",
        "  centroids = []\n",
        "  for i in range(k):\n",
        "    # print(np.random.shuffle(x))\n",
        "    row_ind = np.random.choice(x.shape[0],replace=False)\n",
        "    row = x[row_ind,:]\n",
        "    y_hat = i\n",
        "    centroids.append(row.T)\n",
        "  return (np.array(centroids))\n",
        "\n",
        "\n",
        "\n",
        "######################################################################\n",
        "\n",
        "\n",
        "# X_train_df = pd.DataFrame(X_train)\n",
        "# # print(X_train_df)\n",
        "# # print(np.shape(cent))\n",
        "\n",
        "\n",
        "############# Implement Lloyd's algorithm #########################\n",
        "\n",
        "\n",
        "Train_err = []\n",
        "Test_err = []\n",
        "cc = []\n",
        "cctt = []\n",
        "for K in k:\n",
        "  cent = random_centroids(X_train,K)\n",
        "  cent = cent.T\n",
        "  converge = True\n",
        "  tot_dist = []\n",
        "  dist = np.zeros((n,K))\n",
        "  dist2 = np.zeros((n1,K))\n",
        "\n",
        "  it = 0\n",
        "  iter = []\n",
        "\n",
        "  while converge!=d:\n",
        "    cent_old = cent\n",
        "    y_hat = []\n",
        "    #dist = np.apply_along_axis(lambda u: ((X_train - u)**2).sum(axis=1),0,cent) # find distance between each data point and each cluster centroid\n",
        "    for i in range(K):\n",
        "      cent1 = cent[:,i].reshape(d,1)\n",
        "      cent2 = np.dot(cent1,np.ones((1,n))).T\n",
        "      dist[:,i] = np.linalg.norm((X_train - cent2),ord=2,axis=1)\n",
        "      # cent_2 = np.dot(cent1,np.ones((1,n1))).T\n",
        "      # dist2[:,i] = np.linalg.norm((X_test - cent_2),ord=2,axis=1)\n",
        "    \n",
        "\n",
        "    y_hat = np.argmin(dist,axis=1) # cluster assignment\n",
        "    c = np.sum(np.min(dist,axis=1),axis=0)\n",
        "    # ctt = np.sum(np.min(dist2,axis=1),axis=0)\n",
        "\n",
        "    # print(c)\n",
        "    # cc.append(c)\n",
        "    # cctt.append(ctt)\n",
        "\n",
        "\n",
        "\n",
        "  #####################################################################\n",
        "    # Update Step\n",
        "    new_cent = []\n",
        "    for g in range(K):\n",
        "      sum = []\n",
        "      for h in range(n):\n",
        "        if y_hat[h] == g:\n",
        "          sum.append(X_train[h])\n",
        "      sum = np.array(sum)\n",
        "      o = np.mean(sum,axis=0)\n",
        "      # sum = np.mean(sum,axis=0)\n",
        "      new_cent.append(o)\n",
        "\n",
        "    cent = np.array(new_cent)\n",
        "    cent = cent.T\n",
        "\n",
        "    # for i in range(10):\n",
        "    #   ind = np.argwhere(y_hat == i).flatten()\n",
        "    #   cent[:,i] = np.mean(X_train[ind],axis=0)\n",
        "  #####################################################################\n",
        "\n",
        "    it = it + 1\n",
        "   \n",
        "    iter.append(it)\n",
        "\n",
        "    #Checking error\n",
        "    # err = 0\n",
        "    # for u in range(n):\n",
        "    #   if y_hat[u] != labels_train[u]:\n",
        "    #     err = err+1\n",
        "    # print(err*100/n)\n",
        "\n",
        "    #Convergence checking\n",
        "    converge = 0\n",
        "    for h in range(len(cent)):\n",
        "      if np.linalg.norm(cent[h] - cent_old[h]) <= 0.001:\n",
        "        converge = converge + 1\n",
        "\n",
        "    \n",
        "  #Train_err.append((1/n) * np.apply_along_axis(lambda u: np.mean(np.min(np.linalg.norm((X_train - u),ord=2,axis=1),axis=1),axis=0),0,cent))\n",
        "  # Test_err = (1/m) * np.apply_along_axis(lambda u: np.linalg.norm((X_test - u),ord=2,axis=1),0,cent)\n",
        "\n",
        "  ################ Training Error ######################\n",
        "  dist = np.zeros((n,K))\n",
        "  for i in range(K):\n",
        "    cent1 = cent[:,i].reshape(d,1)\n",
        "    cent2 = np.dot(cent1,np.ones((1,n))).T\n",
        "    dist[:,i] = np.linalg.norm((X_train - cent2),ord=2,axis=1)**2\n",
        "    cent_2 = np.dot(cent1,np.ones((1,n1))).T\n",
        "    dist2[:,i] = np.linalg.norm((X_test - cent_2),ord=2,axis=1)\n",
        "\n",
        "\n",
        "  Train_err.append((1/n) * np.sum(np.min(dist,axis=1),axis=0))\n",
        "  Test_err.append((1/n1) * np.sum(np.min(dist2,axis=1),axis=0))\n",
        "\n",
        "  # ################ Test Error ##########################\n",
        "\n",
        "\n",
        "  # dist = np.zeros((m,K))\n",
        "  # for i in range(K):\n",
        "  #   cent1 = cent[:,i].reshape(d,1)\n",
        "  #   cent2 = np.dot(cent1,np.ones((1,n))).T\n",
        "  #   dist[:,i] = np.linalg.norm((X_test - cent2),ord=2,axis=1)**2\n",
        "\n",
        "\n",
        "  # Test_err.append(np.mean(np.min(dist,axis=1),axis=0))\n",
        "  \n",
        "\n",
        "\n",
        "plt.plot(k,Train_err,label='Train error')\n",
        "plt.plot(k,Test_err,label='Test error')\n",
        "plt.xlabel('k values')\n",
        "plt.ylable('Error')\n",
        "plt.title('Train Error and Test Error vs k values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ph0fozN7yb0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}