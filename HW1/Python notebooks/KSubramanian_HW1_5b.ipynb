{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gAvIkX2KtGM",
        "outputId": "a58f663c-e5aa-4550-cffc-d6ab16ab4d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error(%) = 14.804999999999998\n",
            "Test Error(%) =  14.67\n"
          ]
        }
      ],
      "source": [
        "#Problem 5 \n",
        "#sub problem b\n",
        "# Name: Karthick Subramanian\n",
        "# ASUID: 1223408524\n",
        "\n",
        "# import required libararies\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "d = 784\n",
        "clas = 10\n",
        "\n",
        "# Obtain the data set\n",
        "(X_train, labels_train), (X_test, labels_test) = mnist.load_data()\n",
        "#mndata = MNIST(r'/content/train-images-idx3-ubyte.gz')\n",
        "#X_train, labels_train = map(np.array, mndata.load_training())\n",
        "#X_test, labels_test = map(np.array, mndata.load_testing())\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "\n",
        "X_train = X_train.reshape(60000,784)\n",
        "X_test = X_test.reshape(10000,784)\n",
        "\n",
        "##  Training function ##\n",
        "def train(X,y,lambd):\n",
        "  X_Trans = np.transpose(X)\n",
        "  I = np.identity(d)\n",
        "  w = []\n",
        "  Inv = np.linalg.solve(np.dot(X_Trans,X) + lambd*I, I)\n",
        "  X_t_y = np.dot(X_Trans,y)\n",
        "  w_cap = np.dot(Inv,X_t_y)\n",
        "  return w_cap\n",
        "\n",
        "## Function for one hot encoding ##\n",
        "def one_hot_encode(y,cla):\n",
        "  ohe = np.zeros((y.shape[0],cla))\n",
        "  for i,ys in enumerate(y):\n",
        "    ohe[i][ys] = 1\n",
        "  return ohe\n",
        "\n",
        "## Predict function ##\n",
        "def predict(W,x_prime):\n",
        "  w_Trans = np.transpose(W)\n",
        "  a,b = np.shape(x_prime)\n",
        "  result = []\n",
        "  for i in range(a):\n",
        "    x_i_prime = x_prime[i]\n",
        "    x_i_prime = np.transpose(x_i_prime)\n",
        "    result.append(np.argmax(np.dot(w_Trans,x_i_prime)))\n",
        "\n",
        "  return result\n",
        "\n",
        "## Error function ##\n",
        "def Error(pred, X, labels):\n",
        "  a,b = np.shape(X)\n",
        "  Error = 0\n",
        "  for i in range(a):\n",
        "    if labels[i] != pred[i]:\n",
        "      Error = Error + 1\n",
        "  return Error / a\n",
        "\n",
        "# change the labels to a distribution using one hot encoding\n",
        "Y_train = one_hot_encode(labels_train, clas)\n",
        "\n",
        "# Train the model to get W_cap\n",
        "W_Cap = train(X_train,Y_train,0.0004)\n",
        "\n",
        "# Find the error by comparing the predicted value and the labels\n",
        "Err_Train = Error(predict(W_Cap,X_train),X_train, labels_train)\n",
        "Err_Test = Error(predict(W_Cap,X_test), X_test, labels_test)\n",
        "\n",
        "#print the Error %\n",
        "print(\"Train Error(%) =\",Err_Train*100)\n",
        "print(\"Test Error(%) = \",Err_Test*100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2ZWFzDYuWOk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}