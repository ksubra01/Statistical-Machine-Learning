{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2lODnVXoXAn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajw_7Oo2TMhP",
        "outputId": "d2aaf8e2-a022-4dc5-d11c-f023912361c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4232
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1,  1250] loss: 2.138\n",
            "[1,  2500] loss: 1.815\n",
            "[1,  3750] loss: 1.665\n",
            "[1,  5000] loss: 1.547\n",
            "[1,  6250] loss: 1.500\n",
            "[1,  7500] loss: 1.415\n",
            "[1,  8750] loss: 1.397\n",
            "[1, 10000] loss: 1.319\n",
            "[1, 11250] loss: 1.310\n",
            "[1, 12500] loss: 1.247\n",
            "Test Accuracy =  57\n",
            "Train_accuracy =  58\n",
            "[2,  1250] loss: 1.172\n",
            "[2,  2500] loss: 1.170\n",
            "[2,  3750] loss: 1.141\n",
            "[2,  5000] loss: 1.121\n",
            "[2,  6250] loss: 1.103\n",
            "[2,  7500] loss: 1.080\n",
            "[2,  8750] loss: 1.033\n",
            "[2, 10000] loss: 1.053\n",
            "[2, 11250] loss: 1.048\n",
            "[2, 12500] loss: 1.028\n",
            "Test Accuracy =  64\n",
            "Train_accuracy =  67\n",
            "[3,  1250] loss: 0.935\n",
            "[3,  2500] loss: 0.929\n",
            "[3,  3750] loss: 0.954\n",
            "[3,  5000] loss: 0.926\n",
            "[3,  6250] loss: 0.919\n",
            "[3,  7500] loss: 0.897\n",
            "[3,  8750] loss: 0.880\n",
            "[3, 10000] loss: 0.899\n",
            "[3, 11250] loss: 0.894\n",
            "[3, 12500] loss: 0.876\n",
            "Test Accuracy =  67\n",
            "Train_accuracy =  72\n",
            "[4,  1250] loss: 0.770\n",
            "[4,  2500] loss: 0.775\n",
            "[4,  3750] loss: 0.794\n",
            "[4,  5000] loss: 0.811\n",
            "[4,  6250] loss: 0.797\n",
            "[4,  7500] loss: 0.780\n",
            "[4,  8750] loss: 0.803\n",
            "[4, 10000] loss: 0.772\n",
            "[4, 11250] loss: 0.802\n",
            "[4, 12500] loss: 0.778\n",
            "Test Accuracy =  72\n",
            "Train_accuracy =  78\n",
            "[5,  1250] loss: 0.694\n",
            "[5,  2500] loss: 0.701\n",
            "[5,  3750] loss: 0.684\n",
            "[5,  5000] loss: 0.708\n",
            "[5,  6250] loss: 0.704\n",
            "[5,  7500] loss: 0.692\n",
            "[5,  8750] loss: 0.743\n",
            "[5, 10000] loss: 0.703\n",
            "[5, 11250] loss: 0.703\n",
            "[5, 12500] loss: 0.713\n",
            "Test Accuracy =  71\n",
            "Train_accuracy =  79\n",
            "[6,  1250] loss: 0.574\n",
            "[6,  2500] loss: 0.624\n",
            "[6,  3750] loss: 0.612\n",
            "[6,  5000] loss: 0.615\n",
            "[6,  6250] loss: 0.637\n",
            "[6,  7500] loss: 0.631\n",
            "[6,  8750] loss: 0.647\n",
            "[6, 10000] loss: 0.659\n",
            "[6, 11250] loss: 0.642\n",
            "[6, 12500] loss: 0.661\n",
            "Test Accuracy =  72\n",
            "Train_accuracy =  82\n",
            "[7,  1250] loss: 0.530\n",
            "[7,  2500] loss: 0.536\n",
            "[7,  3750] loss: 0.512\n",
            "[7,  5000] loss: 0.586\n",
            "[7,  6250] loss: 0.567\n",
            "[7,  7500] loss: 0.586\n",
            "[7,  8750] loss: 0.582\n",
            "[7, 10000] loss: 0.576\n",
            "[7, 11250] loss: 0.590\n",
            "[7, 12500] loss: 0.596\n",
            "Test Accuracy =  72\n",
            "Train_accuracy =  84\n",
            "[8,  1250] loss: 0.451\n",
            "[8,  2500] loss: 0.470\n",
            "[8,  3750] loss: 0.499\n",
            "[8,  5000] loss: 0.511\n",
            "[8,  6250] loss: 0.490\n",
            "[8,  7500] loss: 0.521\n",
            "[8,  8750] loss: 0.527\n",
            "[8, 10000] loss: 0.537\n",
            "[8, 11250] loss: 0.562\n",
            "[8, 12500] loss: 0.540\n",
            "Test Accuracy =  72\n",
            "Train_accuracy =  86\n",
            "[9,  1250] loss: 0.400\n",
            "[9,  2500] loss: 0.426\n",
            "[9,  3750] loss: 0.425\n",
            "[9,  5000] loss: 0.464\n",
            "[9,  6250] loss: 0.475\n",
            "[9,  7500] loss: 0.479\n",
            "[9,  8750] loss: 0.494\n",
            "[9, 10000] loss: 0.508\n",
            "[9, 11250] loss: 0.487\n",
            "[9, 12500] loss: 0.509\n",
            "Test Accuracy =  71\n",
            "Train_accuracy =  85\n",
            "[10,  1250] loss: 0.362\n",
            "[10,  2500] loss: 0.376\n",
            "[10,  3750] loss: 0.382\n",
            "[10,  5000] loss: 0.427\n",
            "[10,  6250] loss: 0.431\n",
            "[10,  7500] loss: 0.410\n",
            "[10,  8750] loss: 0.422\n",
            "[10, 10000] loss: 0.454\n",
            "[10, 11250] loss: 0.436\n",
            "[10, 12500] loss: 0.473\n",
            "Test Accuracy =  71\n",
            "Train_accuracy =  88\n",
            "[11,  1250] loss: 0.292\n",
            "[11,  2500] loss: 0.330\n",
            "[11,  3750] loss: 0.359\n",
            "[11,  5000] loss: 0.375\n",
            "[11,  6250] loss: 0.376\n",
            "[11,  7500] loss: 0.404\n",
            "[11,  8750] loss: 0.408\n",
            "[11, 10000] loss: 0.415\n",
            "[11, 11250] loss: 0.445\n",
            "[11, 12500] loss: 0.429\n",
            "Test Accuracy =  71\n",
            "Train_accuracy =  88\n",
            "[12,  1250] loss: 0.280\n",
            "[12,  2500] loss: 0.302\n",
            "[12,  3750] loss: 0.317\n",
            "[12,  5000] loss: 0.343\n",
            "[12,  6250] loss: 0.333\n",
            "[12,  7500] loss: 0.346\n",
            "[12,  8750] loss: 0.377\n",
            "[12, 10000] loss: 0.383\n",
            "[12, 11250] loss: 0.402\n",
            "[12, 12500] loss: 0.402\n",
            "Test Accuracy =  72\n",
            "Train_accuracy =  91\n",
            "[13,  1250] loss: 0.248\n",
            "[13,  2500] loss: 0.304\n",
            "[13,  3750] loss: 0.299\n",
            "[13,  5000] loss: 0.317\n",
            "[13,  6250] loss: 0.332\n",
            "[13,  7500] loss: 0.331\n",
            "[13,  8750] loss: 0.320\n",
            "[13, 10000] loss: 0.363\n",
            "[13, 11250] loss: 0.357\n",
            "[13, 12500] loss: 0.373\n",
            "Test Accuracy =  71\n",
            "Train_accuracy =  91\n",
            "[14,  1250] loss: 0.233\n",
            "[14,  2500] loss: 0.250\n",
            "[14,  3750] loss: 0.250\n",
            "[14,  5000] loss: 0.271\n",
            "[14,  6250] loss: 0.296\n",
            "[14,  7500] loss: 0.336\n",
            "[14,  8750] loss: 0.335\n",
            "[14, 10000] loss: 0.321\n",
            "[14, 11250] loss: 0.350\n",
            "[14, 12500] loss: 0.363\n",
            "Test Accuracy =  72\n",
            "Train_accuracy =  91\n",
            "[15,  1250] loss: 0.214\n",
            "[15,  2500] loss: 0.238\n",
            "[15,  3750] loss: 0.262\n",
            "[15,  5000] loss: 0.270\n",
            "[15,  6250] loss: 0.286\n",
            "[15,  7500] loss: 0.273\n",
            "[15,  8750] loss: 0.299\n",
            "[15, 10000] loss: 0.330\n",
            "[15, 11250] loss: 0.301\n",
            "[15, 12500] loss: 0.326\n",
            "Test Accuracy =  70\n",
            "Train_accuracy =  92\n",
            "[16,  1250] loss: 0.184\n",
            "[16,  2500] loss: 0.241\n",
            "[16,  3750] loss: 0.230\n",
            "[16,  5000] loss: 0.268\n",
            "[16,  6250] loss: 0.251\n",
            "[16,  7500] loss: 0.271\n",
            "[16,  8750] loss: 0.327\n",
            "[16, 10000] loss: 0.289\n",
            "[16, 11250] loss: 0.316\n",
            "[16, 12500] loss: 0.300\n",
            "Test Accuracy =  71\n",
            "Train_accuracy =  92\n",
            "[17,  1250] loss: 0.196\n",
            "[17,  2500] loss: 0.202\n",
            "[17,  3750] loss: 0.215\n",
            "[17,  5000] loss: 0.264\n",
            "[17,  6250] loss: 0.269\n",
            "[17,  7500] loss: 0.275\n",
            "[17,  8750] loss: 0.275\n",
            "[17, 10000] loss: 0.303\n",
            "[17, 11250] loss: 0.270\n",
            "[17, 12500] loss: 0.285\n",
            "Test Accuracy =  70\n",
            "Train_accuracy =  93\n",
            "[18,  1250] loss: 0.159\n",
            "[18,  2500] loss: 0.195\n",
            "[18,  3750] loss: 0.194\n",
            "[18,  5000] loss: 0.218\n",
            "[18,  6250] loss: 0.232\n",
            "[18,  7500] loss: 0.242\n",
            "[18,  8750] loss: 0.253\n",
            "[18, 10000] loss: 0.269\n",
            "[18, 11250] loss: 0.254\n",
            "[18, 12500] loss: 0.268\n",
            "Test Accuracy =  70\n",
            "Train_accuracy =  93\n",
            "[19,  1250] loss: 0.160\n",
            "[19,  2500] loss: 0.197\n",
            "[19,  3750] loss: 0.202\n",
            "[19,  5000] loss: 0.227\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-293fac25a3c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 150, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(150, 50, 5)\n",
        "        self.fc1 = nn.Linear(50 * 5 * 5, 100)\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.fc3 = nn.Linear(50,10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "  \n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "\n",
        "Train_acc = []\n",
        "Test_acc = []\n",
        "\n",
        "def accuracy(X):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in X:\n",
        "          images, labels = data\n",
        "          outputs = net(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "  return correct * 100 // total\n",
        "\n",
        "for epoch in range(30):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 1250 == 1249:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1250:.3f}')\n",
        "            running_loss = 0.0\n",
        "    train_accuracy = accuracy(trainloader)\n",
        "    test_accuracy = accuracy(testloader)\n",
        "    print(\"Test Accuracy = \",test_accuracy)\n",
        "    print(\"Train_accuracy = \",train_accuracy)\n",
        "    Train_acc.append(train_accuracy)\n",
        "    Test_acc.append(test_accuracy)\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The values of hyper parameters are:\")\n",
        "print(\"Learning Rate=\",0.001)\n",
        "print(\"Momentum=\",0.9)\n",
        "print(\"M=\",150)\n",
        "print(\"Max Train and Test accuracies are:\")\n",
        "print(max(Train_acc))\n",
        "print(max(Test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuzt5E98ZK2q",
        "outputId": "c41636f5-af49-4469-b427-14d8ca2bff3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The values of hyper parameters are:\n",
            "Learning Rate= 0.001\n",
            "Momentum= 0.9\n",
            "M= 150\n",
            "Max Train and Test accuracies are:\n",
            "93\n",
            "72\n"
          ]
        }
      ]
    }
  ]
}